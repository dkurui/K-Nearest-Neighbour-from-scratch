{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NumPy, pandas and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imputation(df):\n",
    "    data = df.copy()\n",
    "    data = data.drop(columns=[\"ID\",\"CLASS\"])\n",
    "    flist = list(data.select_dtypes(include=['float','int']).columns)\n",
    "    clist = list(data.select_dtypes(include=['category']).columns)\n",
    "    olist = list(data.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    dicti={}\n",
    "    for c in flist:\n",
    "        if (data[c].isnull().all() == True):\n",
    "            data[c].fillna(0,inplace=True)\n",
    "            dicti[c]=0\n",
    "        else:\n",
    "            data[c].fillna(data[c].mean(),inplace=True)\n",
    "            dicti[c]=data[c].mean()\n",
    "    for k in clist:\n",
    "        if (data[k].isnull().all() == True):\n",
    "            data[k].fillna(data[k].cat.categories[0],inplace=True)\n",
    "            dicti[k]=data[k].cat.categories[0]\n",
    "        else:\n",
    "            data[k].fillna(data[k].mode()[0],inplace=True)\n",
    "            dicti[k] = data[k].mode()[0]\n",
    "    for z in olist:\n",
    "        if (data[z].isnull().all() == True):\n",
    "            data[z].fillna(\"\",inplace=True)\n",
    "            dicti[z] = \"\"\n",
    "        else:\n",
    "            data[z].fillna(data[z].mode()[0],inplace=True)\n",
    "            dicti[z] = data[z].mode()[0]\n",
    "    data = data.assign(CLASS=df[\"CLASS\"].values)\n",
    "    data = data.assign(ID=df[\"ID\"].values)\n",
    "    return data,dicti\n",
    "\n",
    "def apply_imputation(df,dicti):\n",
    "    test = df.copy()\n",
    "    test = test.drop(columns=[\"ID\",\"CLASS\"])\n",
    "    flist_t = list(test.select_dtypes(include=['float','int']).columns)\n",
    "    clist_t = list(test.select_dtypes(include=['category']).columns)\n",
    "    olist_t = list(test.select_dtypes(include=['object']).columns)\n",
    "    for c in flist_t:\n",
    "        if (test[c].isnull().all() == True):\n",
    "            test[c].fillna(0,inplace=True)\n",
    "        else:\n",
    "            test[c].fillna(dicti[c],inplace=True)\n",
    "    for k in clist_t:\n",
    "        if (test[k].isnull().all() == True):\n",
    "            test[k].fillna(test[k].cat.categories[0],inplace=True)\n",
    "        else:\n",
    "            test[k].fillna(dicti[k],inplace=True)\n",
    "    for z in olist_t:\n",
    "        if (test[z].isnull().all() == True):\n",
    "            test[z].fillna(\"\",inplace=True)\n",
    "        else:\n",
    "            test[z].fillna(dicti[z],inplace=True)\n",
    "    test = test.assign(CLASS=df[\"CLASS\"].values)\n",
    "    test = test.assign(ID=df[\"ID\"].values)\n",
    "    return test\n",
    "\n",
    "def create_normalization(data,normalizationtype=\"minmax\"):\n",
    "    df = data.copy() # create a copy of the data\n",
    "    df = df.drop(columns=[\"ID\",\"CLASS\"])\n",
    "    df.select_dtypes(include=['float','int'])\n",
    "    if(normalizationtype == \"minmax\"):\n",
    "        dicti = {}\n",
    "        for x in df.columns:\n",
    "            mini = df[x].min()\n",
    "            maxi = df[x].max()\n",
    "            df[x] = [(y - mini)/(maxi-mini) for y in df[x]]\n",
    "            dicti[x] =(\"minmax\",mini,maxi)\n",
    "        df = df.assign(CLASS=data[\"CLASS\"].values)\n",
    "        return df,dicti\n",
    "    elif(normalizationtype ==\"zscore\"): #The function is written for the zscore normalization though not used. \n",
    "        dict2 = {}\n",
    "        for x in df.columns:\n",
    "            meane = df[x].mean()\n",
    "            stdi = df[x].std()\n",
    "            df[x] = df[x].apply(lambda x:(x-meane)/stdi)\n",
    "            dict2[x] =(\"zscore\",meane,stdi)\n",
    "        df = df.assign(CLASS=data[\"CLASS\"].values)\n",
    "        return df,dict2\n",
    "    \n",
    "def apply_normalization(test,normalization):\n",
    "    dft = test.copy()\n",
    "    dft = dft.drop(columns=[\"ID\"])\n",
    "    flist = list(dft.select_dtypes(include=['float']).columns)\n",
    "    for c in flist:\n",
    "        m = normalization[c][1] #m represents the minimum value from the normalization dictionary\n",
    "        h = normalization[c][2] #h represents the maximum value from the normalization dictionary\n",
    "        dft[c] = [(y - m)/(h-m) for y in dft[c]]\n",
    "    return dft\n",
    "\n",
    "def euclidean(arrone,arrtwo):\n",
    "    summ= 0\n",
    "    for x in range(len(arrone)):\n",
    "        diff = (arrone[x] - arrtwo[x])\n",
    "        squared = diff * diff\n",
    "        summ = squared + summ\n",
    "    return np.sqrt(summ)\n",
    "def SortValue(value):\n",
    "    return value[1]\n",
    "def getclass(sorti,trainlabels):\n",
    "    #The function returns the class labels for the K number of classes.\n",
    "    classes = []\n",
    "    for x in range(len(sorti)):\n",
    "        classes.append(trainlabels[sorti[x][0]]) \n",
    "    return classes\n",
    "def highestclass(K_classes):\n",
    "    #The function returns a 2-D array with the class and its occurences/count number\n",
    "    unique, counts = np.unique(K_classes, return_counts=True)\n",
    "    final = []\n",
    "    for i in range(len(unique)):\n",
    "        final.append([unique[i],counts[i]])\n",
    "    return final\n",
    "\n",
    "def finalclass(arrone):\n",
    "    #The function returns the class with the highest occurence as the reverse value is true(descending)\n",
    "    finalarr = sorted(arrone,key=SortValue,reverse=True)\n",
    "    fin = finalarr[0][0]\n",
    "    return fin\n",
    "\n",
    "def accuracy(predictions,correctlabels):\n",
    "    count = 0\n",
    "    numrows = len(correctlabels)\n",
    "    for x,y in zip(predictions.index, range(numrows)):\n",
    "        pos = np.argmax(np.array(predictions.loc[x]))\n",
    "        if(predictions.columns[pos] == correctlabels[y]):\n",
    "            count += 1\n",
    "    accuracy = count/numrows\n",
    "    return accuracy\n",
    "\n",
    "def brier_score(df,correctlabels):\n",
    "    col_list = list(df.columns)\n",
    "    rw = 0\n",
    "    b_score = 0\n",
    "    for index, row in df.iterrows():\n",
    "        for col in col_list:\n",
    "            if col == correctlabels[rw]:\n",
    "                val = 1\n",
    "                b = (row[col]-val)**2\n",
    "            else:\n",
    "                val = 0\n",
    "                b = (row[col]-val)**2\n",
    "            b_score = b_score + b\n",
    "        rw+=1\n",
    "    b_score = b_score/(len(df))\n",
    "    return b_score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the class kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class kNN():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self,df,normalizationtype=\"minmax\"):\n",
    "        self.imputed,self.imputer = create_imputation(df)\n",
    "        self.normalized,self.normalizer = create_normalization(self.imputed,normalizationtype)\n",
    "        self.traininglabels = self.normalized[\"CLASS\"].astype('category')\n",
    "        self.labels = list(self.normalized[\"CLASS\"].unique())\n",
    "        self.labels.sort()\n",
    "        self.labels = np.array(self.labels)\n",
    "        self.trainingdata = self.normalized.drop(columns=[\"CLASS\"],axis=1)\n",
    "        self.trainingdata = np.array(self.trainingdata)\n",
    "    def predict(self,df,k=1):\n",
    "        self.testimp = apply_imputation(df,self.imputer)\n",
    "        self.testnorm = apply_normalization(self.testimp,self.normalizer)\n",
    "        self.testnorm = self.testnorm.drop(columns=[\"CLASS\"],axis=1)\n",
    "        self.testnorm = np.array(self.testnorm)\n",
    "        \n",
    "        creator = np.zeros(shape=(len(self.testnorm),len(self.labels)))\n",
    "        data = pd.DataFrame(creator,columns=self.labels)\n",
    "        incre = 0\n",
    "        predicted = []\n",
    "        for row in self.testnorm:\n",
    "            indexi = 0\n",
    "            sorti =[]\n",
    "            dist_values = []\n",
    "            for rowe in self.trainingdata:\n",
    "                dist = euclidean(row,rowe)\n",
    "                dist_values.append([indexi,dist])\n",
    "                indexi+=1\n",
    "            sorti = sorted(dist_values, key=SortValue)\n",
    "            sorti = sorti[:k]\n",
    "            K_classes = getclass(sorti,self.traininglabels)\n",
    "            ranked = highestclass(K_classes)\n",
    "            cl =[]\n",
    "            for i in range(len(ranked)):\n",
    "                cl.append(ranked[i][0])\n",
    "            co = pd.DataFrame(columns=cl)\n",
    "            h= data.columns.difference(co.columns)\n",
    "            for d in h:\n",
    "                data.loc[incre:incre,d] = 0\n",
    "            b = data.columns.intersection(co.columns)\n",
    "            for v in b:\n",
    "                for i in range(len(ranked)):\n",
    "                    if (v == ranked[i][0]):\n",
    "                        data.loc[incre:incre,v] = (ranked[i][1]/k)\n",
    "            incre +=1\n",
    "            pclass = finalclass(ranked)\n",
    "            predicted.append(pclass)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.05 s.\n",
      "Testing time (k=1): 0.62 s.\n",
      "Testing time (k=3): 0.63 s.\n",
      "Testing time (k=5): 0.68 s.\n",
      "Testing time (k=7): 0.73 s.\n",
      "Testing time (k=9): 0.78 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.504673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.488058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.474019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.470723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.483674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Brier score\n",
       "1  0.747664     0.504673\n",
       "3  0.663551     0.488058\n",
       "5  0.579439     0.474019\n",
       "7  0.598131     0.470723\n",
       "9  0.616822     0.483674"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "knn_model = kNN()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "knn_model.fit(glass_train_df)\n",
    "print(\"Training time: {0:.2f} s.\".format(time.perf_counter()-t0))\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "k_values = [1,3,5,7,9]\n",
    "results = np.empty((len(k_values),2))\n",
    "\n",
    "for i in range(len(k_values)):\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = knn_model.predict(glass_test_df,k=k_values[i])\n",
    "    print(\"Testing time (k={0}): {1:.2f} s.\".format(k_values[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=k_values,columns=[\"Accuracy\",\"Brier score\"])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set (k=1): 1.00\n",
      "Brier score on training set (k=1): 0.00\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "predictions = knn_model.predict(glass_train_df,k=1)\n",
    "print(\"Accuracy on training set (k=1): {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"Brier score on training set (k=1): {0:.2f}\".format(brier_score(predictions,train_labels)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
